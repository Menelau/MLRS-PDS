import pandas as pd
import os
import glob
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from pymfe.mfe import MFE
import pickle

# Upload the data test not the meta feature
meta_features2 = []
for files in glob.glob('s2_test_processed_csv/*'):
    print(files)

    files_name = files.split("\\")[1]
    print(files_name)
    df = pd.read_csv(files)
    # print(df)
    Xmf1 = df.iloc[:, :-1].values
    # print(Xmf)
    ymf1 = df.iloc[:, -1].values

    # Extract general, statistical and information-theoretic measures
    mfe1 = MFE(groups=['general', 'statistical', 'info-theory', 'Relative Landmarking', 'Subsampling Landmarking',
                      'Clustering', 'Concept', 'Itemset', 'Complexity', 'all'])
    mfe1.fit(Xmf1)
    meta_features_from_file2 = mfe1.extract()
    print(meta_features_from_file2)

    print(meta_features_from_file2)
    print(len(meta_features_from_file2))
    print("-----------------test------------------")
    print(meta_features_from_file2[1])
    meta_features2.append(meta_features_from_file2[1])
    f_meta_features2 = [np.nan_to_num(i) for i in meta_features2]  # I replaced nan with 0 specially for knn
    print(f_meta_features2)
    name = files.split(".")[0].split("\\")[1]
    print(name)
    #et the number in the name of the dataset
    string = name
    number = ''.join(filter(str.isdigit, string))
    print(number)
    number = int(number)

test_meta = f_meta_features2

y = []
# df = pd.read_csv('data300.xlsx')
df = pd.read_excel('dataframe_friedman.xlsx')

# esme data ha ro hazf kon vase rank dadan
df1 = df.iloc[:, 1:]
# df2 = df1.drop(index=0)
print(df1)
# print(df2)
# entekhabe chand column baraye mohayese pool ha dar yek method.  #df1 base hastesh hesam
KNORAE = df1.iloc[:, [1, 9, 17, 25, 33, 41, 49]]
METADES = df1.iloc[:, [2, 10, 18, 26, 34, 42, 50]]
KNORAU = df1.iloc[:, [3, 11, 19, 27, 35, 43, 51]]
DESMI = df1.iloc[:, [4, 12, 20, 28, 36, 44, 52]]
DESP = df1.iloc[:, [5, 13, 21, 29, 37, 45, 53]]
MLA = df1.iloc[:, [6, 14, 22, 30, 38, 46, 54]]
OLA = df1.iloc[:, [7, 15, 23, 31, 39, 47, 55]]
algorithm = KNORAE
# algorithm = METADES
# algorithm = KNORAU
# algorithm = DESMI
# algorithm = DESP
# algorithm = MLA
# algorithm = OLA
rank_knorae = algorithm.rank(ascending=False, method='min', axis=1)
print(algorithm)
highest_value_col_name = algorithm.idxmax(axis=1)
print(highest_value_col_name)
original_list = highest_value_col_name
print(original_list)
f_y = original_list
print("List size:", len(f_y))
if number in range(len(f_y)):
    del f_y[number - 1]
    y = np.array(f_y)
    y = y.reshape(-1)
    print(y)
    print("y  size:", len(y))


def extract_meta_features(folder):
    meta_features_file = os.path.join(folder, "meta_features.npy")
    meta_features = np.load(meta_features_file)
    return meta_features


# to get and save the meta feature
# meta_features = []
# for file in glob.glob('testt_288_csv/*'):
#     print(file)
# 
#     file_name = file.split("\\")[1]
#     print(file_name)
#     # item_name = items.split("\\")[2].split(".")[0].split("_")[2]
#     # print(item_name)
#     # ss = file_name.split("_")[0]
#     # print(ss)
#     # rr = ss.split("/")[1] + item_name.split("_")[6]
#     # print(rr)
#     # hh = item_name.split("_")[1]
#     # print(hh)
# 
#     df = pd.read_csv(file)
#     # print(df)
# 
#     Xmf = df.iloc[:, :-1].values
#     # print(Xmf)
#     ymf = df.iloc[:, -1].values
#     # print(ymf)
# 
# 
#     # Extract general, statistical and information-theoretic measures
#     mfe = MFE(groups=['general', 'statistical', 'info-theory', 'Relative Landmarking', 'Subsampling Landmarking',
#                       'Clustering', 'Concept', 'Itemset', 'Complexity', 'all'])
#     mfe.fit(Xmf)
#     meta_features_from_file = mfe.extract()
#     print(meta_features_from_file)
# 
#     # meta_features_from_file22 = [np.nan_to_num(i) for i in meta_features_from_file]  # I replaced nan with 0
#     # print(meta_features_from_file22)
#     print(meta_features_from_file[1]) #in mishe meta feature hesammm
#     meta_features.append(meta_features_from_file[1])
#     meta_features2 = [np.nan_to_num(i).tolist() for i in meta_features]
#     print(meta_features2)
#     print("meta_features2_len:", len(meta_features2))
# 
# with open("meta_features3.pkl", "wb") as file:
#     pickle.dump(meta_features2, file)


# to load the meta feature
for file in glob.glob('meta_features/*'):
    print(file)
    with open(file, "rb") as file:
        meta_features = pickle.load(file)
        print("meta_features_len:", len(meta_features))

        list1 = meta_features[:number-1]
        list2 = meta_features[number:]
        mergedList = [*list1, *list2]
        # print(mergedList)
        print("mergedList  size:", len(mergedList))
        f_meta_features = mergedList
        print("X size:", len(f_meta_features))

X = f_meta_features

# Convert to a numpy array
meta_features = np.array(meta_features)

# Create a KNN classifier with k=1
knn = KNeighborsClassifier(n_neighbors=1)

knn.fit(X, y)

test_meta = f_meta_features2

# Use the classifier to predict the label of the test data
predictions = knn.predict(test_meta)

# Print the predicted y label
print("Predicted y label: ", predictions)


